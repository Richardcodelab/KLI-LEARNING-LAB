# query_normalizer.py
import os
import json
import pandas as pd

try:
    import openai
except Exception:
    openai = None


class QueryNormalizer:
    """
    ğŸ”  ê²€ìƒ‰ì–´ ì •ê·œí™” ë„ìš°ë¯¸
    - CSV ê¸°ë°˜ ë§¤í•‘(user_pattern â†’ canonical_term, synonyms)
    - GPT(OpenAI API) ê¸°ë°˜ í™•ì¥ (í–¥í›„ Gemma ë“±ìœ¼ë¡œ êµì²´ ê°€ëŠ¥)
    """

    def __init__(self, csv_path="keyword_mapping.csv", use_ai=True, model="gpt-3.5-turbo"):
        self.csv_path = csv_path
        self.use_ai = use_ai
        self.model = model
        self.mapping_df = self._load_mapping(csv_path)
        self._setup_openai()

    # -------------------------------------
    # ë‚´ë¶€ ì„¤ì •
    # -------------------------------------
    def _setup_openai(self):
        """í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°"""
        if openai is None:
            return
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            openai.api_key = api_key

    def _load_mapping(self, path):
        """CSV ë§¤í•‘í‘œ ë¡œë“œ"""
        if not os.path.exists(path):
            print(f"âš ï¸ ë§¤í•‘ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
            return pd.DataFrame(columns=["user_pattern", "canonical_term", "category", "synonyms", "weight"])

        try:
            df = pd.read_csv(path)
            for col in ["user_pattern", "canonical_term", "category", "synonyms", "weight"]:
                if col not in df.columns:
                    df[col] = None
            print(f"âœ… ë§¤í•‘í‘œ {len(df)}í–‰ ë¡œë“œ ì™„ë£Œ")
            return df
        except Exception as e:
            print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
            return pd.DataFrame(columns=["user_pattern", "canonical_term", "category", "synonyms", "weight"])

    # -------------------------------------
    # CSV ë§¤í•‘ ë¡œì§
    # -------------------------------------
    def map_with_csv(self, query: str):
        """CSV ê¸°ë°˜ ë§¤í•‘ ê²€ìƒ‰"""
        if self.mapping_df.empty:
            return []
        q = str(query).strip().lower()
        terms = []
        for _, row in self.mapping_df.iterrows():
            pattern = str(row.get("user_pattern", "")).lower()
            if not pattern:
                continue
            if pattern in q or q in pattern:
                canonical = str(row.get("canonical_term", "")).strip()
                if canonical:
                    terms.append(canonical)
                synonyms = str(row.get("synonyms", "")).strip()
                if synonyms:
                    for s in synonyms.split("|"):
                        s = s.strip()
                        if s:
                            terms.append(s)
        return sorted(list(set([t for t in terms if t])))

    # -------------------------------------
    # GPT / LLM ê¸°ë°˜ ë§¤í•‘
    # -------------------------------------
    def map_with_ai(self, query: str):
        """GPTë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ì–´ í™•ì¥"""
        if not self.use_ai or openai is None or not hasattr(openai, "ChatCompletion"):
            return []
        prompt = f"""
        ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì´ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤: "{query}"
        í•œêµ­ì–´ í•™ìˆ  ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ì— ì í•©í•˜ë„ë¡ í•µì‹¬ í‚¤ì›Œë“œ 5~8ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.
        ë¶ˆìš©ì–´ ì œê±°, ë™ì˜ì–´ì™€ ê´€ë ¨ì–´ë¥¼ í¬í•¨í•˜ì„¸ìš”.
        JSON ë°°ì—´(list) í˜•íƒœë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        """
        try:
            resp = openai.ChatCompletion.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
            )
            content = resp.choices[0].message["content"].strip()
            data = json.loads(content)
            if isinstance(data, list):
                return [str(x).strip() for x in data if str(x).strip()]
            return []
        except Exception as e:
            print(f"âš ï¸ GPT ë³€í™˜ ì‹¤íŒ¨: {e}")
            return []

    # -------------------------------------
    # í†µí•© ì •ê·œí™”
    # -------------------------------------
    def normalize(self, query: str):
        """CSV + AI ê²°ê³¼ ë³‘í•©"""
        csv_terms = self.map_with_csv(query)
        ai_terms = self.map_with_ai(query)
        bundle = [query] + csv_terms + ai_terms
        bundle = [t for t in bundle if t]
        bundle = sorted(list(set(bundle)), key=lambda x: len(x))
        return bundle[:12]  # ìµœëŒ€ 12ê°œê¹Œì§€ë§Œ
